{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATA EXPLORATION`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TOPIC: FILMS ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Group ID`: 17\n",
    "\n",
    "`Group Member`:\n",
    "- 22127404_Tạ Minh Thư\n",
    "- 22127359_Chu Thúy Quỳnh\n",
    "- 22127302_Nguyễn Đăng Nhân"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('films_data.csv', 'r', encoding='utf-8-sig')\n",
    "\n",
    "data = {}\n",
    "first_line = file.readline().strip().split('\\t')\n",
    "for val in first_line:\n",
    "    data[val] = []\n",
    "\n",
    "for line in file:\n",
    "    line_vals = line.strip().split('\\t')   \n",
    "    for i in range(len(line_vals)):\n",
    "        data[first_line[i]].append(line_vals[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of each row\n",
    "Each row represents a specific movie, detailing information about its release, performance, genre, and key contributors (director, writer, and cast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1000\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows:', len(data['Rank']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of each column\n",
    "- `Ranks`: The film's rank in the top lifetime grosses.\n",
    "- `Titles`: The film's name.\n",
    "- `Foreign %`: The percentage of the foreign grosses in the film's worldwide grosses.\n",
    "- `Domestic %`: The percentage of the domestic grosses in the film's worldwide grosses.\n",
    "- `Years`: The year that the film was first released.\n",
    "- `Genres`: The genre(s) associated with each film.\n",
    "- `Directors`: The director(s) of each film.\n",
    "- `Writers`: The writer(s) credited for each film.\n",
    "- `Casts`: The main cast members of each film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 9\n"
     ]
    }
   ],
   "source": [
    "print('Number of columns:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: <class 'str'>\n",
      "Title: <class 'str'>\n",
      "Foreign %: <class 'str'>\n",
      "Domestic %: <class 'str'>\n",
      "Year: <class 'str'>\n",
      "Genre: <class 'str'>\n",
      "Director: <class 'str'>\n",
      "Writer: <class 'str'>\n",
      "Cast: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for col_name, col_value in data.items():\n",
    "    print(f'{col_name}: {type(col_value[0])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert Percentage Columns: Convert Foreign % and Domestic % to numeric values by removing the '%' symbol and changing the data type to floats. If the value in these columns is '-', it indicates that the foreign gross accounts for 100% of the film's worldwide grosses, and the domestic gross is considered 0%.\n",
    "\n",
    "- Standardize Year Data Type: Ensure Year is an integer for easy numerical analysis.\n",
    "\n",
    "- Split Genres: Split the values in Genre into separate columns or lists for better analysis of each genre individually.\n",
    "\n",
    "- Director and Writer Parsing: If needed, split multiple directors or writers into lists to analyze individual contributions.\n",
    "\n",
    "- Cast Parsing: Similarly, parse the Cast column into individual actor names or convert to lists, which will make it easier to analyze actor appearances across movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rank'] = [int(rank.replace(',', '')) for rank in data['Rank']]\n",
    "\n",
    "data['Foreign %'] = [float(value.rstrip('%')) for value in data['Foreign %']]\n",
    "\n",
    "data['Domestic %'] = [\n",
    "    float(value.replace('<', '').rstrip('%')) if value != '-' else 0 \n",
    "    for value in data['Domestic %']\n",
    "]\n",
    "\n",
    "data['Year'] = [int(year) for year in data['Year']]\n",
    "\n",
    "data['Genre'] = [genres.split(', ') for genres in data['Genre']]\n",
    "\n",
    "data['Director'] = [directors.split(', ') for directors in data['Director']]\n",
    "\n",
    "data['Writer'] = [writers.split(', ') for writers in data['Writer']]\n",
    "\n",
    "\n",
    "data['Cast'] = [actors.split(', ') for actors in data['Cast']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: <class 'int'>\n",
      "Title: <class 'str'>\n",
      "Foreign %: <class 'float'>\n",
      "Domestic %: <class 'float'>\n",
      "Year: <class 'int'>\n",
      "Genre: <class 'list'>\n",
      "Director: <class 'list'>\n",
      "Writer: <class 'list'>\n",
      "Cast: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for col_name, col_value in data.items():\n",
    "    print(f'{col_name}: {type(col_value[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `normalize_data` is created to make data comparisons easier and more consistent. This is done by cleaning up the data and making sure all values look the same regardless of formatting differences.\n",
    "- The function processes each cell in the DataFrame row:\n",
    "- If the cell contains a list:\n",
    "    - It processes each item in the list by converting the item to lowercase.\n",
    "    - Strips leading or trailing spaces.\n",
    "    - Sorts the list elements using sorted() to ensure the order doesn’t matter (so ['b', 'a'] becomes ['a', 'b']).\n",
    "    - Converts the cleaned list into a string format so that Pandas can handle it for comparisons.\n",
    "- If the cell does not contain a list:\n",
    "    - It simply converts the value to lowercase.\n",
    "    - Strips any extra spaces.\n",
    "- This cleaned and consistent version of the row is then returned.\n",
    "- After that, we wil applies `normalize_data` function to each row of the DataFrame.\n",
    "- The line `num_duplicated_rows = normalized_df.duplicated().sum()` checks for duplicates in the normalized DataFrame:\n",
    "- `normalized_df.duplicated()` returns a Series (a single column of data) where each row is marked as True if it is a duplicate of a previous row.\n",
    "- `.sum()` counts how many True values are in this Series, giving the total number of duplicated rows.\n",
    "- If duplicates are found, it will create a new DataFrame containing all rows that are considered duplicates:\n",
    "    - `keep=False` marks all rows as True if they are duplicates, including the first occurrence, so that all duplicate rows can be seen.\n",
    "- The code then prints the duplicated rows for examination.\n",
    "- If no duplicates are found, it simply prints a message saying, \"No duplicated data found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data has 0 duplicated rows (excluding the first occurrence in each group).\n",
      "No duplicated data found.\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def normalize_data(row):\n",
    "    # Normalize each cell by converting to lowercase, stripping spaces,\n",
    "    # sorting lists if any, and converting lists to strings for comparison\n",
    "    return row.apply(\n",
    "        lambda x: str(sorted([str(v).strip().lower() for v in x])) if isinstance(x, list) \n",
    "        else str(x).strip().lower()\n",
    "    )\n",
    "\n",
    "# Apply normalization to each row\n",
    "normalized_df = df.apply(normalize_data, axis=1)\n",
    "\n",
    "num_duplicated_rows = normalized_df.duplicated().sum()\n",
    "print(f\"The raw data has {num_duplicated_rows} duplicated rows (excluding the first occurrence in each group).\")\n",
    "\n",
    "if num_duplicated_rows > 0:\n",
    "    duplicates = df[normalized_df.duplicated(keep=False)]\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicated data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `check_missing_data` takes one argument `data`, which is a dictionary where the key is the column name, and the value is a list of values for that column.\n",
    "- `missing_data_results`: a dictionary to store the names of columns that have missing data.\n",
    "- `missing_ratio_results`: a dictionary to store the missing data ratio for each column.\n",
    "- `missing_indices`: a list to store the indices of missing values in the current column.\n",
    "- The `for` loop iterates over each value in the column, using `enumerate` to get both the index and the value.\n",
    "- Missing data conditions:\n",
    "  + The value is `None`.\n",
    "  + The value is an empty string or a string with only whitespace.\n",
    "- If a missing value is found, its index is appended to `missing_indices`.\n",
    "- If any missing indices are found for the current column, they are added to `missing_data_results`, with the column name as the key and the list of missing indices as the value.\n",
    "- Missing data ratio:\n",
    "  + For each column, the ratio of missing data is calculated by dividing the number of missing values by the total number of values in the column.\n",
    "  + This ratio is saved in `missing_ratio_results` as a floating-point value.\n",
    "- If no missing data is found, the function prints `\"No missing data found\"`. On the other hand, if missing data is present, it displays the column name and the indices where the missing data is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data found\n",
      "\n",
      "Missing ratio per column:\n",
      "Column 'Rank' missing ratio: 0.00%\n",
      "Column 'Title' missing ratio: 0.00%\n",
      "Column 'Foreign %' missing ratio: 0.00%\n",
      "Column 'Domestic %' missing ratio: 0.00%\n",
      "Column 'Year' missing ratio: 0.00%\n",
      "Column 'Genre' missing ratio: 0.00%\n",
      "Column 'Director' missing ratio: 0.00%\n",
      "Column 'Writer' missing ratio: 0.00%\n",
      "Column 'Cast' missing ratio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def check_missing_data(data):\n",
    "    columns = list(data.keys())\n",
    "    missing_data = {}\n",
    "    missing_ratio_results = {}\n",
    "\n",
    "    for col in columns:\n",
    "        col_values = data[col]\n",
    "        missing_indices = []\n",
    "\n",
    "        for index, value in enumerate(col_values):\n",
    "            if value is None or (isinstance(value, str) and value.strip() == ''):\n",
    "                missing_indices.append(index)\n",
    "                \n",
    "        if missing_indices:\n",
    "            missing_data[col] = missing_indices\n",
    "        missing_ratio = len(missing_indices) / len(col_values)\n",
    "        missing_ratio_results[col] = missing_ratio\n",
    "\n",
    "    if not missing_data:\n",
    "        print(\"No missing data found\")\n",
    "    \n",
    "    for col, indices in missing_data.items():\n",
    "        print(f\"Missing data in column '{col}' at indices: {indices}\")\n",
    "    print(\"\\nMissing ratio per column:\")\n",
    "    \n",
    "    for col, ratio in missing_ratio_results.items():\n",
    "        print(f\"Column '{col}' missing ratio: {ratio:.2%}\") \n",
    "        \n",
    "    return missing_data, missing_ratio_results\n",
    "missing_data, missing_ratio_results = check_missing_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because of the missing ratio of all columns is 0.00% and there's no duplicated data, it means there is no missing data. The dataset is ready for analysis without the need for imputation or data cleaning related to missing values or duplicated data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
