{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATA EXPLORATION`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TOPIC: FILMS ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Group ID`: 17\n",
    "\n",
    "`Group Member`:\n",
    "- 22127404_Tạ Minh Thư\n",
    "- 22127359_Chu Thúy Quỳnh\n",
    "- 22127302_Nguyễn Đăng Nhân"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('films_data.csv', 'r', encoding='utf-8-sig')\n",
    "\n",
    "data = {}\n",
    "first_line = file.readline().strip().split('\\t')\n",
    "for val in first_line:\n",
    "    data[val] = []\n",
    "\n",
    "for line in file:\n",
    "    line_vals = line.strip().split('\\t')   \n",
    "    for i in range(len(line_vals)):\n",
    "        data[first_line[i]].append(line_vals[i])\n",
    "        \n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of each row\n",
    "Each row represents a specific movie, detailing information about its release, performance, genre, and key contributors (director, writer, and cast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 1000\n"
     ]
    }
   ],
   "source": [
    "n_row, n_col = data_df.shape\n",
    "print('Number of columns:', n_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of each column\n",
    "- `Ranks`: The film's rank in the top lifetime grosses.\n",
    "- `Titles`: The film's name.\n",
    "- `Foreign %`: The percentage of the foreign grosses in the film's worldwide grosses.\n",
    "- `Domestic %`: The percentage of the domestic grosses in the film's worldwide grosses.\n",
    "- `Years`: The year that the film was first released.\n",
    "- `Genres`: The genre(s) associated with each film.\n",
    "- `Directors`: The director(s) of each film.\n",
    "- `Writers`: The writer(s) credited for each film.\n",
    "- `Casts`: The main cast members of each film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 9\n"
     ]
    }
   ],
   "source": [
    "print('Number of columns:', n_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank          object\n",
       "Title         object\n",
       "Foreign %     object\n",
       "Domestic %    object\n",
       "Year          object\n",
       "Genre         object\n",
       "Director      object\n",
       "Writer        object\n",
       "Cast          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert Percentage Columns: Convert Foreign % and Domestic % to numeric values by removing the '%' symbol and changing the data type to floats. If the value in these columns is '-', it indicates that the foreign gross accounts for 100% of the film's worldwide grosses, and the domestic gross is considered 0%.\n",
    "\n",
    "- Standardize Year Data Type: Ensure Year is an integer for easy numerical analysis.\n",
    "\n",
    "- Split Genres: Split the values in Genre into separate columns or lists for better analysis of each genre individually.\n",
    "\n",
    "- Director and Writer Parsing: If needed, split multiple directors or writers into lists to analyze individual contributions.\n",
    "\n",
    "- Cast Parsing: Similarly, parse the Cast column into individual actor names or convert to lists, which will make it easier to analyze actor appearances across movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Rank'] = data_df['Rank'].str.replace(',', '').astype(int)\n",
    "\n",
    "data_df['Foreign %'] = data_df['Foreign %'].str.rstrip('%').astype(float)\n",
    "\n",
    "data_df['Domestic %'] = data_df['Domestic %'].apply(\n",
    "    lambda x: float(x.replace('<', '').rstrip('%')) if x != '-' else 0.0\n",
    ")\n",
    "\n",
    "data_df['Genre'] = data_df['Genre'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "\n",
    "data_df['Director'] = data_df['Director'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "\n",
    "data_df['Writer'] = data_df['Writer'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "\n",
    "data_df['Cast'] = data_df['Cast'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank            int64\n",
       "Title          object\n",
       "Foreign %     float64\n",
       "Domestic %    float64\n",
       "Year           object\n",
       "Genre          object\n",
       "Director       object\n",
       "Writer         object\n",
       "Cast           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `normalize_data` is created to make data comparisons easier and more consistent. This is done by cleaning up the data and making sure all values look the same regardless of formatting differences.\n",
    "- The function processes each cell in the DataFrame row:\n",
    "- If the cell contains a list:\n",
    "    - It processes each item in the list by converting the item to lowercase.\n",
    "    - Strips leading or trailing spaces.\n",
    "    - Sorts the list elements using sorted() to ensure the order doesn’t matter (so ['b', 'a'] becomes ['a', 'b']).\n",
    "    - Converts the cleaned list into a string format so that Pandas can handle it for comparisons.\n",
    "- If the cell does not contain a list:\n",
    "    - It simply converts the value to lowercase.\n",
    "    - Strips any extra spaces.\n",
    "- This cleaned and consistent version of the row is then returned.\n",
    "- After that, we wil applies `normalize_data` function to each row of the DataFrame.\n",
    "- The line `num_duplicated_rows = normalized_df.duplicated().sum()` checks for duplicates in the normalized DataFrame:\n",
    "- `normalized_df.duplicated()` returns a Series (a single column of data) where each row is marked as True if it is a duplicate of a previous row.\n",
    "- `.sum()` counts how many True values are in this Series, giving the total number of duplicated rows.\n",
    "- If duplicates are found, it will create a new DataFrame containing all rows that are considered duplicates:\n",
    "    - `keep=False` marks all rows as True if they are duplicates, including the first occurrence, so that all duplicate rows can be seen.\n",
    "- The code then prints the duplicated rows for examination.\n",
    "- If no duplicates are found, it simply prints a message saying, \"No duplicated data found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data has 0 duplicated rows.\n",
      "No duplicated data found.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "def normalize_data(row):\n",
    "    return row.apply(\n",
    "        lambda x: str(sorted([str(v).strip().lower() for v in x])) if isinstance(x, list) \n",
    "        else str(x).strip().lower()\n",
    "    )\n",
    "\n",
    "normalized_df = df.apply(normalize_data, axis=1)\n",
    "\n",
    "num_duplicated_rows = normalized_df.duplicated().sum()\n",
    "print(f\"The raw data has {num_duplicated_rows} duplicated rows.\")\n",
    "\n",
    "if num_duplicated_rows > 0:\n",
    "    duplicates = df[normalized_df.duplicated(keep=False)]\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicated data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df.isnull()` creates a DataFrame of the same size as df, with True where values are NaN (missing) and False otherwise.\n",
    "- `df.isnull().sum()` counts the number of True values (i.e., missing values) for each column.\n",
    "- Dividing `df.isnull().sum()` by `len(df)` calculates the proportion of missing values for each column.\n",
    "- Multiplying by 100 converts this proportion to a percentage, resulting in missing_ratio_results, which is a Pandas Series showing the percentage of missing data per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing ratio per column:\n",
      "Column 'Rank': 0.00% missing\n",
      "Column 'Title': 0.00% missing\n",
      "Column 'Foreign %': 0.00% missing\n",
      "Column 'Domestic %': 0.00% missing\n",
      "Column 'Year': 0.00% missing\n",
      "Column 'Genre': 0.00% missing\n",
      "Column 'Director': 0.00% missing\n",
      "Column 'Writer': 0.00% missing\n",
      "Column 'Cast': 0.00% missing\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "def check_missing_data(data):\n",
    "\n",
    "    \n",
    "    missing_ratio_results = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "    print(\"\\nMissing ratio per column:\")\n",
    "    for col, ratio in missing_ratio_results.items():\n",
    "        print(f\"Column '{col}': {ratio:.2f}% missing\")\n",
    "\n",
    "    return missing_ratio_results.to_dict()\n",
    "\n",
    "missing_ratio_results = check_missing_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because of the missing ratio of all columns is 0.00% and there's no duplicated data, it means there is no missing data. The dataset is ready for analysis without the need for imputation or data cleaning related to missing values or duplicated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA DISTRIBUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **For numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Foreign %</th>\n",
       "      <th>Domestic %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower_quartile</th>\n",
       "      <td>250.8</td>\n",
       "      <td>51.1</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>500.5</td>\n",
       "      <td>60.5</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper_quartile</th>\n",
       "      <td>750.2</td>\n",
       "      <td>69.4</td>\n",
       "      <td>48.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Rank  Foreign %  Domestic %\n",
       "min                1.0       13.2         0.0\n",
       "lower_quartile   250.8       51.1        30.6\n",
       "median           500.5       60.5        39.5\n",
       "upper_quartile   750.2       69.4        48.9\n",
       "max             1000.0      100.0        86.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = data_df.select_dtypes(include='number')\n",
    "\n",
    "def lower_quartile(col):\n",
    "    return col.quantile(0.25)\n",
    "\n",
    "def upper_quartile(col):\n",
    "    return col.quantile(0.75)\n",
    "\n",
    "def median(col):\n",
    "  return col.median()\n",
    "min_vals = numeric_cols.min()\n",
    "max_vals = numeric_cols.max()\n",
    "lower_quartile_vals = numeric_cols.apply(lower_quartile)\n",
    "median_vals = numeric_cols.apply(median)\n",
    "upper_quartile_vals = numeric_cols.apply(upper_quartile)\n",
    "\n",
    "num_col_info_df = pd.DataFrame({\n",
    "    \"min\": min_vals,\n",
    "    \"lower_quartile\": lower_quartile_vals,\n",
    "    \"median\": median_vals,\n",
    "    \"upper_quartile\": upper_quartile_vals,\n",
    "    \"max\": max_vals\n",
    "}).T\n",
    "\n",
    "num_col_info_df = num_col_info_df.round(1)\n",
    "num_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **For non-numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) # For clearly\n",
    "pd.set_option('display.max_columns', None) # For clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_values</th>\n",
       "      <th>value_ratios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>988</td>\n",
       "      <td>{'The Jungle Book': 0.2, 'The Lion King': 0.2, 'Beauty and the Beast': 0.2, 'The Little Mermaid'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>55</td>\n",
       "      <td>{'2019': 4.9, '2017': 4.9, '2016': 4.8, '2018': 4.7, '2014': 4.5, '2013': 4.3, '2012': 4.2, '201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>343</td>\n",
       "      <td>{'Action,Adventure,Sci-Fi': 6.4, 'Action,Adventure,Thriller': 3.1, 'Action,Adventure,Sci-Fi,Thri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Director</th>\n",
       "      <td>535</td>\n",
       "      <td>{'Steven Spielberg': 2.2, 'Tim Burton': 1.0, 'Ridley Scott': 1.0, 'Robert Zemeckis': 1.0, 'Micha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Writer</th>\n",
       "      <td>930</td>\n",
       "      <td>{'M. Night Shyamalan': 0.6, 'Melissa Rosenberg,Stephenie Meyer': 0.4, 'Chris Morgan,Gary Scott T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cast</th>\n",
       "      <td>980</td>\n",
       "      <td>{'Keanu Reeves,Laurence Fishburne,Carrie-Anne Moss,Hugo Weaving': 0.3, 'Vin Diesel,Paul Walker,M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_values  \\\n",
       "Title           988   \n",
       "Year             55   \n",
       "Genre           343   \n",
       "Director        535   \n",
       "Writer          930   \n",
       "Cast            980   \n",
       "\n",
       "                                                                                                 value_ratios  \n",
       "Title     {'The Jungle Book': 0.2, 'The Lion King': 0.2, 'Beauty and the Beast': 0.2, 'The Little Mermaid'...  \n",
       "Year      {'2019': 4.9, '2017': 4.9, '2016': 4.8, '2018': 4.7, '2014': 4.5, '2013': 4.3, '2012': 4.2, '201...  \n",
       "Genre     {'Action,Adventure,Sci-Fi': 6.4, 'Action,Adventure,Thriller': 3.1, 'Action,Adventure,Sci-Fi,Thri...  \n",
       "Director  {'Steven Spielberg': 2.2, 'Tim Burton': 1.0, 'Ridley Scott': 1.0, 'Robert Zemeckis': 1.0, 'Micha...  \n",
       "Writer    {'M. Night Shyamalan': 0.6, 'Melissa Rosenberg,Stephenie Meyer': 0.4, 'Chris Morgan,Gary Scott T...  \n",
       "Cast      {'Keanu Reeves,Laurence Fishburne,Carrie-Anne Moss,Hugo Weaving': 0.3, 'Vin Diesel,Paul Walker,M...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col_info = {}\n",
    "\n",
    "for col in data_df.select_dtypes(exclude='number').columns:\n",
    "    non_missing_values = data_df[col].dropna()\n",
    "    non_missing_values = non_missing_values.apply(lambda x: ','.join(map(str, x)) if isinstance(x, list) else x)\n",
    "    if data_df[col].dtype.name == 'category' or data_df[col].dtype == 'object':  # Categorical columns\n",
    "        num_values = non_missing_values.nunique()\n",
    "\n",
    "    value_counts = non_missing_values.value_counts(normalize=True) * 100\n",
    "    value_ratios = value_counts.to_dict()\n",
    "\n",
    "    cat_col_info[col] = {\n",
    "        'num_values': num_values,\n",
    "        'value_ratios': value_ratios\n",
    "    }\n",
    "\n",
    "cat_col_info_df = pd.DataFrame(cat_col_info).T\n",
    "cat_col_info_df['value_ratios'] = cat_col_info_df['value_ratios'].apply(lambda x: {k: round(v, 1) for k, v in x.items()})\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check constraints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checking_grosses(df: pd.DataFrame) -> bool:\n",
    "    consistency_check = (df['Foreign %'] + df['Domestic %'] == 100)\n",
    "\n",
    "    return consistency_check.all()\n",
    "\n",
    "checking_grosses(data_df) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4999999999999716"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(100 - (data_df[\"Foreign %\"] + data_df[\"Domestic %\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Domestic %'] = 100 - data_df['Foreign %']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_grosses(data_df) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataFrame2CSV(df: pd.DataFrame, save_path: str, sep: str = ',', encoding: str = 'utf-8') -> bool:\n",
    "    try:\n",
    "        df.to_csv(save_path, sep=sep, encoding=encoding, index=False)\n",
    "    except:\n",
    "        raise ModuleNotFoundError\n",
    "        # return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name = \"cleaned_data.csv\"\n",
    "saveDataFrame2CSV(data_df, os.path.join(\"./\", f\"{save_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank            int64\n",
       "Title          object\n",
       "Foreign %     float64\n",
       "Domestic %    float64\n",
       "Year            int64\n",
       "Genre          object\n",
       "Director       object\n",
       "Writer         object\n",
       "Cast           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv(\"cleaned_data.csv\")\n",
    "cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
